[
    {
        "id_": "3dbae77e-fdb4-443c-9180-94eb3b89b80f",
        "text": "# 1 Introduction\n\nOptimization problems are prevalent in numerous modern scientific and engineering domains, necessitating increasingly intricate and compute intensive algorithms. They can also be of different nature depending on the application domain, the underlying computational complexity, the extent of information made available to the solvers, etc. This paper addresses blackbox continuous optimization problems requiring large-scale parallel architectures. More precisely, the goal is to find a real-valued solution x ∈ Rn that minimizes (or maximizes) a continuous objective function f: Rn → R. The function f is given as blackbox, meaning that no predetermined mathematical knowledge is available about the function, such as its derivatives or any information about its structure (e.g. is the function smooth or convex?). A blackbox optimization algorithm then operates by probing f for input x, obtaining the corresponding fitness value f(x), and proceeding accordingly for the rest of the search process in an iterative manner. Blackbox optimization problems have received considerable attention for being essential."
    },
    {
        "id_": "d8da599b-e932-4f54-985b-551391237502",
        "text": "# Blackbox Optimization Algorithms\n\nIn many application domains, these include complex engineering models or numerical simulations, and generally application fields where problem specifics remain elusive. For instance, applications in aeronautics necessitate optimizing aerodynamics through simulations of airflow around vehicles, nuclear physics involves simulating heat or particle diffusion to optimize the dimensions of containment vessels, urban transportation systems require optimizing a traffic flow determined by the patterns of stoplights, etc. Traditional gradient-based approaches cannot be applied to such problems. This led to the development of various classes of blackbox optimization algorithms, also known as derivative-free algorithms [34, 16]."
    },
    {
        "id_": "90a92e64-bc3c-4405-9cab-a3727a7a8fb9",
        "text": "# CMA-ES Algorithm\n\nWe are interested here in the so-called CMA-ES (Covariance Matrix Adaptation Evolution Strategy) algorithm [26], and more specifically in its IPOP-CMA-ES [10] (Increasing Population CMA-ES) variant. CMA-ES is a state-of-the-art blackbox optimization algorithm, which is, along with its variants, the best optimizer in the GECCO black-box optimization competition [62]. CMA-ES also has applications in many fields: neural networks [40], applied physics and engineering (e.g. for the design of thermal cloaks [19], optic cloaks [20], lenses [53], gas turbines [28]), autonomous sailing [43, 42], hydrology [63], sensor networks [5], wind energy [58], solar energy [33], to cite a few.\n\nCMA-ES is an iterative algorithm: at each iteration, it samples a set of points (called the population) using a probability distribution determined by the current mean point and a n×n covariance matrix, with n the dimension of the objective function f. The qualities of the points are evaluated with f and used to update the mean point and the matrix for the next iteration. These updates involve linear algebra operations and aim at directing the search towards interesting neighbouring areas. The IPOP-CMA-ES [10] (Increasing Population CMA-ES) restart strategy improves CMA-ES, especially for more complex problems [62]. After one CMA-ES execution (also referred to as a descent) ends, because it is for example trapped in a local optimum, a next CMA-ES descent is started with a greater population size, and so on. This enables IPOP-CMA-ES to employ increasingly thorough searches, at the cost of more and more function evaluations, to eventually find better optima."
    },
    {
        "id_": "cccc4bed-9ad8-4693-8822-b5527da6bae9",
        "text": "# Challenges and Approaches\n\nCMA-ES and IPOP-CMA-ES can thus be used to tackle challenging blackbox optimization problems. However, large optimization problems still require a lot of compute power, because the function evaluations can be individually time-consuming, and/or because many function evaluations (i.e. CMA-ES iterations) can be needed to solve complex problems. Two main approaches can be distinguished in the literature to accelerate CMA-ES and IPOP-CMA-ES for large optimization problems.\n\nThe first approach focuses on reducing the cost of the linear algebra operations while retaining as much quality as possible in the search for solutions. This is done by storing a reduced number of parameters instead of a full matrix of n² parameters, leading to reduced costs for updating and using the matrix. These so-called large-scale CMA-ES variants can store k < n vectors of n parameters [36, 39, 6, 38, 37, 29], or only n parameters [59], or even only the sampled points [32]. Subsequent works compared the respective merits of some of those large-scale variants [67, 55, 66] taking into account their lower ability to retain information about the local function landscape, which leads to less effective convergence and to a lower quality for the final solution.\n\nThe second approach does not degrade the solution quality but relies on parallelism for the independent function evaluations [49, 11]. This was for example used for specific application domains [40, 17, 30]. Additionally, certain parameters can be adapted during the CMA-ES descent [11], in the hope of finding settings which best fit the parallel hardware. Another way of using parallelism is to run multiple CMA-ES descents concurrently, while trying to improve the convergence of any given descent using information from the other descents. In optimization, this method is known as the island model. Some island models were proposed for the original CMA-ES [50, 49, 60]. Such island models have also been used in specific domains [21, 47, 52], or for multi-objective optimization [13]. Some works also implement an island model for a large-scale CMA-ES variant [7, 14, 15]. However, to the"
    },
    {
        "id_": "8020bfa3-e797-4baf-ab98-8870bfa2385d",
        "text": "# Best of our knowledge, there currently exists no work on the parallelization of IPOP-CMA-ES\n\nwhich implies running descents of increasing population sizes. In this paper, we thus focus on the use of parallelism and HPC to solve large optimization problems with IPOP-CMA-ES by speeding up both the linear algebra operations and the function evaluations. We present the following contributions.\n\n- We first show how the CMA-ES linear algebra operations can be accelerated thanks to BLAS and LAPACK routines. This requires the rewrite of some of these operations in order to introduce more efficient BLAS routines.\n- We present two parallel strategies for IPOP-CMA-ES to fully exploit a large number of CPU cores (up to several thousand). Such a number of CPU cores implies multiple compute nodes in distributed memory, each node being composed of multiple cores in shared memory. The goal here is to leverage large-scale parallelism (via multiple nodes) to benefit from the increasing number of (parallel) evaluations in IPOP-CMA-ES. The first strategy performs descents in the same order of population size as the original IPOP-CMA-ES, while the second strategy processes concurrently descents of different population sizes.\n- We thoroughly compare MPI[45]+OpenMP[56] implementations of our two strategies on 6144 cores (128 nodes) of the supercomputer Fugaku in order to determine which one is the most relevant on such a large-scale parallel architecture. These comparisons are performed with the reference BBOB[23] (Black-Box Optimization Benchmarking) benchmark for various dimensions and various function evaluation costs. We also present a fine analysis of those results, aggregated in different ways to investigate the impacts of the features of the parallel strategies on performance and on quality, depending on the targeted function, on the dimensions and on the evaluation costs.\n\nThe rest of this paper is organized as follows. In Section 2, we give some background on CMA-ES and on IPOP-CMA-ES. In Section 3, we show how we have introduced BLAS and LAPACK routines, and we describe the proposed parallel strategies. We report our detailed experimental study in Section 4, and we conclude the paper in Section 5."
    },
    {
        "id_": "658cb15b-3423-4afb-a460-8bf2130f8c22",
        "text": "# CMA-ES with increasing population\n\nWe discuss here the main working principles of the Covariance Matrix Adaptation Evolution Strategy with Increasing Population[10] (IPOP-CMA-ES), starting with the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) it is based on."
    },
    {
        "id_": "aa08202a-e7de-4f58-a4d8-ec5c9a0f733c",
        "text": "# The Covariance Matrix Adaptation Evolution Strategy\n\nIn order to find the optimum of an objective function n. At each iteration, CMA-ES samples a best current point (also called the mean or m) in Rf of dimension n, CMA-ES maintains points in Rn (is called the population size) around its mean m according to a normal law distorted along an ellipsoid [25]: see Figure 1. This normal law samples points in a circular fashion around the mean, using more points near the mean, and fewer points away from it. The widths and orientations of the ellipsoid are given by the so-called covariance matrix C. That is, sampling points involves a multivariate normal distribution N(0, C) with zero mean and covariance matrix C. This matrix is n × n shaped: CMA-ES can thus adapt the space in which it samples points to the local shape of the function."
    },
    {
        "id_": "adf704f1-ccd0-4ff9-ab69-143f74cd090d",
        "text": "# Figure 1\n\nConvergence example of CMA-ES on a function space. The white dot indicates the function optimum, the red ellipse the normal law, and the red crosses points sampled according to this law."
    },
    {
        "id_": "8c9c12a3-36df-4c72-90ac-826cab38ae7d",
        "text": "# Algorithm 1\n\nPseudocode of CMA-ES with population size , for an objective function f\n\n1. initialize (mean: m, covariance matrix: C, variance: , evolution path of : p, evolution path of C: pc)\n2. while no stopping criterion met do\n3. . Perform one CMA-ES iteration\n4. for i = 1.. do\n5. xi sample point(m, C, )\n6. for i = 1.. do\n7. fi f (x)i\n8. update (m, C, , p, pc) using (x)i=1.. i and (fi)i=1..\n9. return the sampled point with the best quality\n\nThe mean m, as well as the matrix C, are updated depending on the qualities of the sampled points. These qualities correspond to the evaluations of the function f at all sampled points. For the covariance matrix, this update is called a matrix adaptation. This modification of the matrix aims at distorting the ellipsoid in ways that make it more likely to sample new points in the positions (relative to m) the best previous points were found in. This update requires O( ⇥ n2) operations.\n\nThe scale at which CMA-ES searches for new points is also determined by the variance of the normal law. This variance is updated using a so-called evolution path p [57]. The evolution path is the sum of the last shifts of m. If m is generally shifting in one direction (the better points being farther along a certain axis), then the variance is increased. If m is not shifting in a specific direction (the ellipse remains in the same area, the better points being around m), then the variance is decreased. A similar technique is used for the matrix adaptation, with an evolution path pc.\n\nIn the end, the return value of CMA-ES is the sampled point with the best quality. A high-level algorithm of CMA-ES is given in Algorithm 1, and its convergence is illustrated in Figure 1.\n\nWe now provide a few more mathematical details. Sampling from N (0, C) requires the matrices B and D, where B is a matrix containing orthonormal eigenvectors of C, and D is a diagonal matrix containing the square roots of the eigenvalues of C. Eventually, we want to sample the points xk ∈ Rn from the normal law N (m, 2C). The corresponding equation reads\n\nxk = m + BDzk, 81 ≤ k ≤ (1)\n\nwith zk ∈ Rn sampled from N (0, I), I being the n × n identity matrix. The equation for adapting the covariance matrix C according to the qualities of the newly sampled points then"
    },
    {
        "id_": "a001e6de-7829-4ff5-a029-88574645ad57",
        "text": "# Algorithm 2"
    },
    {
        "id_": "cf74b31f-be36-47d8-8d37-3ccc26374313",
        "text": "# Pseudocode of IPOP-CMA-ES with initial population size\n\nstart, multiplicative factor 2, maximum coefficient Kmax, for an objective function f\n\n1. K &nbsp; &nbsp; 1\n2. while K ≤ Kmax and budget not exhausted do\n3. initialize (mean: m, covariance matrix: C, variance: , evolution path of : p, evolution path of C: pc)\n4. while no stopping criterion met do\n5. process one iteration of CMA-ES (see Algorithm 1, lines 4-8) using m, C, , p, pc and with population size K × start\n6. K &nbsp; &nbsp; K × 2\n7. return the sampled point with the best quality (over all descents)\n\nreads\n\nC = C + cμ ∑i=1K wrk(i)(yiyiT C) + c1(pcpcT C)\n\nwhere cμ ∈ R and c1 ∈ R are learning rate parameters for CMA-ES, wrk(i) ∈ R is a weight depending on the rank of the point xi values having greater weights, and P when sorted by function value (points with better function i=1 wrk(i) = 1), and ∀i ∈ {1, K}, yi ∈ Rn is such that xi = m + yi [24].\n\nwhich requires O(n3) operations with D from the matrix C In turn, computing B involves an eigendecomposition, the function dimension. Updating other variables like pc or p only requires at most O(n2) or O( n) operations and is thus less time-consuming."
    },
    {
        "id_": "7dfa0fe8-916d-497c-ad15-fb8825602c3b",
        "text": "# 2.2 The increasing population restart strategy\n\nCMA-ES is a stochastic algorithm due to the random sampling of points within a distribution. Two executions of Algorithm 1 (also referred to as descents) on the same problem with the same parameters may thus sample different points and return a different best point. One execution may indeed find high quality points the other missed. As such, executing CMA-ES multiple times enables one to increase the quality of the final best point. The exact benefit of these multiple executions will of course depend on the shape of the objective function.\n\nIn order to identify if the search has settled on a local optimum and if the current execution must stop, multiple stopping conditions [9] have been proposed for CMA-ES. The stopping conditions can generally be understood as either the function quality not improving anymore, or the function being locally too flat, or even the sampling distribution being too small (i.e. the mean stops moving, or almost so). The best is then to restart the algorithm (i.e. start a new descent) in the hope of finding even better solution points.\n\nIt has then been shown that increasing the population size for each new restart enables faster convergence [10]. More precisely, this CMA-ES Increasing Population restart scheme (IPOP-CMA-ES) offers the same convergence rate as CMA-ES on simple functions, and a significantly better one on many complex functions. The corresponding high-level algorithm is presented in Algorithm 2. As usual with IPOP-CMA-ES [10, 41, 65, 8], we rely on a multiplicative factor of 2 at each restart for the population size. The initial population size start is hence multiplied by K = 2i for the i-th CMA-ES execution. Hence K ranges from 1 to a certain Kmax, with for example Kmax.\n\nAt each iteration multiple function evaluations are performed and the number of evaluations equals the population size. Since these evaluations are embarrassingly parallel, IPOP-CMA-ES offers thus an increasing degree of parallelism along its execution. When targeting a parallel version of IPOP-CMA-ES, this increasing degree of parallelism is an opportunity to reach important parallel speedups, but one also requires a"
    },
    {
        "id_": "b5c99d5b-8d61-4f14-b3e4-77ae12085b7b",
        "text": "# 3 High performance parallel strategies"
    },
    {
        "id_": "f2884079-2229-43f0-b9e3-1c96ed76b4d5",
        "text": "# 3.1 High performance linear algebra\n\nBefore targeting large-scale parallel speedups via different parallel strategies, we first consider the performance of IPOP-CMA-ES and we study here how BLAS and LAPACK routines can be introduced in CMA-ES (hence in IPOP-CMA-ES). BLAS (Basic Linear Algebra Subprograms1) are high-performance implementations of standard linear algebra operations: vector operations (Level 1 BLAS), matrix-vector operations (Level 2 BLAS), and matrix-matrix operations (Level 3 BLAS). LAPACK (Linear Algebra PACKage2) then relies on BLAS routines to efficiently solve e.g. systems of linear equations, eigenvalue problems, singular value problems, etc. As presented in Section 2.1, multiple steps in CMA-ES actually involve linear algebra operations. We focus on Level 3 BLAS operations with a cubic time complexity for a quadratic input data size: these provide indeed a linear arithmetic intensity which enables their implementation to highly take advantage of current CPU architectures. We have hence been able to introduce BLAS and LAPACK routines in the following three steps, either straightforwardly or thanks to some rewriting of the linear algebra operations.\n\n- The eigendecomposition of the covariance matrix C can first benefit easily from LAPACK by using the dsyev routine.\n- Second, the original equation (see equation 2) for the covariance matrix adaptation does not involve any matrix-matrix multiplication. However, we can first rewrite equation 2 as\n(1 - cμ - c1)C + cμ(Xwrk(i)yiyiT) + c1ppc Xwrk(i) = 1.\n\nC\n\nWe denote by M the n × n matrix equal to P=1 wrk(i)yiyiT. We have then\n\n8(r, c) ∈ J1, nK2, Mr,c = Σi=1n wrk(i)(yi)r(yiT)c = Σi=1n(yi)r(wrk(i)(yiT)c) = Σi=1nAr,iBi,c\n\nwhere A is a n × matrix containing columns of (yi)i=1.. and B is a × n matrix containing rows of (wrk(i)yT)i=1.., namely:\n\n|0|wrk(1)yT|1|\n|---|---|---|\n|0|1|B|\n|B|...|C|\n|C|A = @y1|A|\n|B|wrk(k)yT|C|\n|C|...|yk|\n|B|@|...|\n|wrk()yT| | |\n\nIn the end, we have rewritten the covariance matrix adaptation as\n\nC = (1 - cμ - c1)C + cμA · B + c1ppcT\n\n1See: https://www.netlib.org/blas/\n\n2See: https://www.netlib.org/lapack/"
    },
    {
        "id_": "4f5abfdd-208f-4819-8b95-c5b6895bed94",
        "text": "# 3.2 The parallel strategies\n\nIn this section, we aim at deploying IPOP-CMA-ES on large-scale parallel architectures with thousands of CPU cores. Such architectures are based on multiple nodes (distributed-memory parallelism) composed of few multi-core processors each (shared-memory parallelism): we will thus rely on a hybrid MPI+OpenMP programming, using MPI for inter-process communications and OpenMP for multi-thread parallelism (with T threads in each MPI process). We consider an IPOP-CMA-ES execution with population sizes Kstart, K being a power of 2 ranging from 20 to Kmax (see Algorithm 2). For such an IPOP-CMA-ES execution, we propose here two generic strategies to obtain the best parallel speedups on a fixed (arbitrarily large) number of CPU cores. These strategies will then be specified and compared on a given supercomputer (Fugaku) in Section 4."
    },
    {
        "id_": "5d47ad50-429f-4c19-8fef-9c28c2878e31",
        "text": "# 3.2.1 Parallelism within a CMA-ES descent\n\nFirst of all, in our parallel strategies, each CMA-ES descent will be driven by a dedicated MPI process, hereafter referenced to as the main process. At each iteration of a descent, CMA-ES evaluates the objective function on points: these evaluations can be performed in parallel. In order to obtain the best parallel speedups, we aim at fully exploiting this parallelism level by processing each evaluation on a dedicated CPU core.\n\n- When ≤ T, we can distribute the evaluations on the T threads of the main process."
    },
    {
        "id_": "3b278022-6b8e-4cc6-970a-615711b37247",
        "text": "# core occupancy"
    },
    {
        "id_": "a981c584-479c-4a78-9d10-290097c4dc57",
        "text": "# Figure 2:\n\nIllustration of the core occupancy of a naive version of IPOP-CMA-ES with successive parallel descents."
    },
    {
        "id_": "f5216574-89c2-43ea-80f6-cd21681eee08",
        "text": "# Figure 3:\n\nIllustration of the core occupancy of the K-Replicated strategy.\n\nWhen &gt; T, we have to rely on multiple MPI processes. The main process will thus first generate the list of points where the objective function must be evaluated. These points are then “scattered” (using the corresponding MPI function) on a set of MPI processes. This sets an implicit synchronization among all processes involved in the same descent. Each of these MPI processes will evaluate the function on its points (using its T threads), and the objective function values are finally “gathered” (using again the corresponding MPI function) back to the main process.\n\nFinally, we will also consider multi-thread parallelism for the linear algebra operations performed in each descent (see Section 3.1): this will be detailed in Section 4.2."
    },
    {
        "id_": "aff31b6c-226f-428c-8858-7c2179ab3483",
        "text": "# 3.2.2 The K-Replicated strategy\n\nWhen targeting a parallel IPOP-CMA-ES execution, the first idea that may come to mind is running successively each descent of increasing K value, using the parallelism available within each descent (as described in Section 3.2.1). This is illustrated in Figure 2. The downside of this approach is an overall low CPU core occupancy: since descents with large K have a higher degree of parallelism, most of the CPU cores will be unused for the other descents.\n\nA first solution, hereafter referred to as ‘K-Replicated‘, is to replicate the current K descent unto multiple, independent descents (with the same K value) until all the computing resources are used: see Figure 3. The number of those replicated descents is c/(K × start), where c is the number of CPU cores available. We thus have more simultaneous descents at the start, when K is small, and fewer descents when K is larger; but the overall resource usage remains the same at any time. This way, all CPU cores are being used at all time, and since CMA-ES is a stochastic algorithm, the additional descents can help finding better solutions.\n\nRegarding the implementation, once two K descents are finished, their resources can be used for a subsequent 2K descent. This can be efficiently implemented as in the recursive Algorithm 3 using a hierarchy of MPI communicators, which represent sets of MPI processes."
    },
    {
        "id_": "219e9ed0-b31e-47bc-af37-e49f1b214023",
        "text": "# 3 Pseudocode of the K-Replicated strategy\n\nThe global communicator MPI COMM WORLD (containing all MPI processes) and Kmax are used for the initial call.\n\nprocedure K-Replicated(communicator, K)\nif K > 1 then\nmy rank MPI Comm rank(communicator)\nsize MPI Comm size(communicator)\nmy half comm MPI Comm Split(communicator, my rank ≤ size /2, my rank). splits\n‘communicator‘ in two halves of equal size\nK-Replicated(my half comm, K/2)\nif K ≤ Kmax then\nCMA-ES descent(communicator, K × start)\n\nthat can exchange messages [45]. New communicators can be created by specifying subsets out of a previously existing communicator: each process of the parent communicator indicate which child communicator it belongs to. The global communicator is thus split until the resulting communicators are small enough to be used for descents with K = 1. Then, each time a pair of K = 2i descents from a same parent communicator is finished, the control flows back up to this parent communicator for a K = 2i+1 descent. This is repeated until Kmax is reached and finished as well. Finally, in order to have a distinct random generator seed in each CMA-ES descent, we rely on the current time multiplied by the rank of the MPI process in the global communicator."
    },
    {
        "id_": "4326adbd-11dd-4fc9-beee-74a551281370",
        "text": "# 3.2.3 The K-Distributed strategy\n\nThe K-replicated strategy exploits all the available CPU cores by replicating multiple descents with the same K value. These concurrent K descents increase the chances of finding better solutions for the stochastic IPOP-CMA-ES algorithm. We now consider a second strategy to leverage parallelism among multiple CMA-ES descents for large-scale parallel architectures, which stems from three observations.\n\nFirstly, a descent of population size can be sped-up up to a factor of (provided the communication and linear algebra times are short enough). Secondly, a descent of population K × start usually takes, roughly, K times as long to reach a given quality as a start descent. This can be interpreted as CMA-ES taking in more information about a local landscape of the function before making the choice of where to move next, which requires more time. The benefit of using a larger population size is that, in many cases, the decision will be more ‘informed’, causing CMA-ES to avoid being trapped in a local optimum for longer and ultimately finding better solutions before the end of the descent. Finally, although the previous observation applies in general, there are also cases where, for some quality ranges on some objective functions and for some K values, a K × start descent will be faster or slower than K times the duration of a start descent. We interpret these different behaviors as the impact of the properties of the function landscape on the optimal population size. Note that, especially for more complex functions, the landscape properties can change depending on the region of the search space or on the scale it is observed at.\n\nFrom the first and second observation, we can reasonably expect that several descents, each with a different population size and each running on CPU cores, will generally improve the quality of their current best solution for roughly the same amount of computation time. Then, from the third observation, we can expect that, thanks to their different population sizes, some of these parallel descents will be faster than others to reach certain qualities. Therefore, running"
    },
    {
        "id_": "99ddb162-a03b-4158-b211-c453c5b6427e",
        "text": "# 4 Experimental results on Fugaku\n\nIn this section, we conduct a step-by-step performance analysis on the supercomputer Fugaku of the different parallel and high performance strategies described before. We first start describing our experimental set-up including the setting of the optimization benchmark functions, the considered parallel computing environment and how our parallel strategies are specified for the Fugaku hardware. Then, we report the benefits of using sequential and multi-threaded BLAS/LAPACK routines for CMA-ES. Our main results dealing with the different parallel strategies are then reported and analyzed in a comprehensive manner."
    },
    {
        "id_": "12c3b78f-3153-4b61-aa1a-e2f58de7aa03",
        "text": "# 4.1 Experimental setup\n\nFirstly, for the purpose of comparing the considered algorithms from a pure optimization perspective, and for benchmarking purposes, we consider the COmparing Continuous Optimizers (COCO) [27] framework providing an implementation of the Black-Box Optimization Benchmarking (BBOB)[3] test suite [23]. BBOB is a state-of-the-art blackbox test suite, used in particular in a reference workshop held yearly in the well-established Genetic and Evolutionary Computation Conference (GECCO). More than 200 algorithms were already benchmarked within this framework. BBOB provides a set of 24 continuous functions exposing different properties believed to represent a relatively broad range of blackbox optimization problems that one may encounter in practice. These functions are organized into five groups of increasing difficulty in terms of separability, multi-modality, illness, conditioning, etc. The first group of functions (f1 to f5) are separable. The second group contains functions of low or moderate conditioning (f6 to f9), while the third group contains unimodal functions with high conditioning (f10 to f14). The fourth and fifth group contain multi-modal functions with respectively adequate (f15 to f19) and weak (f20 to f24) global structure. All functions are available in multiple dimensions: in this paper we will study dimensions 10, 40, 200 and 1000. It is to notice that algorithms benchmarked using the BBOB functions, and the underlying COCO platform, usually fix as a budget the total amount of function evaluations that an algorithm is allowed to query. This is in fact a common practice in a blackbox optimization scenario, where the number of function evaluations is considered to be critical. In other words, this allows one to fairly evaluate the ability of an algorithm to search for a high-quality solution, when facing a range of optimization problems with different structural properties and dimensions, while using 3See also: https://numbbo.github.io/data-archive/bbob/"
    },
    {
        "id_": "0badd286-8326-4ec7-a867-c181d183d614",
        "text": "# Evaluation of Blackbox Function Performance\n\nThe minimum number of blackbox function evaluations. As such, although the time it takes to query one blackbox function evaluation may vary across different BBOB functions of different dimensions, the BBOB test suite does not allow to explicitly control the evaluation times, which are in fact very short (less than 9ms in dimension 1000 on average across all functions). In practice however, function evaluation time directly impacts the overall CPU time required to run an algorithm using a specified budget in terms of the total number of function evaluations. Importantly, the time to evaluate a blackbox function is an important feature to account for when fairly assessing the performance of a parallel optimization algorithm, since it can directly impact the computation grain size (i.e. the amount of work performed by each “task” in parallel). Therefore, in our work, and in addition to the broad range of functions provided by the BBOB test suite, we also consider to accommodate different blackbox evaluation times by adding artificial additional times to the BBOB function evaluations. For dimensions 10 and 40, for which BBOB functions have low evaluations costs, we will hence also study additional costs of 1ms, 10ms and 100ms. This will allow us for a more comprehensive and realistic performance assessment of the considered parallel algorithms.\n\nNote that having such greater evaluation times, even for small dimensions, is easily encountered in function optimization. For instance, Roussel et al.[35], use CMA-ES for parameter estimation with objective functions of dimension 8 and evaluation costs in the order of magnitude of the second. Evaluation costs may be even larger when scientific simulations or neural networks are involved: for example, using CMA-ES to find hyper-parameters for neural network training can necessitate evaluation times of 5 or 30 minutes in dimension 19[40].\n\nOther examples of evaluation times include:\n\n- Groundwater bioremediation (about 8 minutes)[48]\n- Aerodynamics of a shape (about 3 or 11 minutes)[31]\n- Molecular docking (4 hours)[44]\n- Automotive crash simulation (about 17 or 29 hours)[18]\n- Neural network trainings for computer vision (0 to 30 minutes)[12]\n- Document classification (average of 2.5 or 5.8 hours)[64]"
    },
    {
        "id_": "0dbe388d-106d-4af8-97d1-b0984d1c6385",
        "text": "# Parallel Performance on Large-Scale Architectures\n\nSecondly, for the purpose of studying the parallel performance of our algorithms on large-scale parallel architectures with thousands of CPU cores, we consider running our algorithms on top of the supercomputer Fugaku. In June 2024, Fugaku was the fourth most powerful supercomputer in the TOP500 list[3], and the first in the world in the HPCG list[2] and in the GRAPH500 BFS list[1]. This massively parallel supercomputer contains 158,976 A64FX CPUs, which are ARM-based architectures developed by Fujitsu with 48 compute cores and 4 assistant cores each [54, 61]. The A64FX is divided in 4 CMGs (core memory groups) of 12 cores each. Each CMG is a NUMA (non-uniform memory access) node. Indeed, the memory space of the CPU consists of a set of HBM2 high-bandwidth memory and 2 levels of cache for each of the 4 CMGs. The CMGs communicate between each others and with the network using a ring bus. The A64FX CPUs are connected by the Tofu Interconnect D [4], a 6D torus topology. For our experiments, we consider using 128 A64FX CPUs of the Fugaku, hence representing a total of 512 CMGs and 6,144 compute cores."
    },
    {
        "id_": "967a4ef5-97ce-431d-8088-277b52da9084",
        "text": "# Implementation Details\n\nRegarding our implementations, they are all based on the sequential C reference code of CMA-ES4, which we modified for the BLAS/LAPACK routines and the MPI+OpenMP parallelization. They are compiled with the Fujitsu C Compiler (version 4.11.1), the Fujitsu OpenMP and MPI libraries, and the Fujitsu thread-parallel implementation of BLAS/LAPACK. We let the C reference code set default values for all parameters, except for the initial mean m, the initial variance and start. In order to better adapt to the BBOB search space, we indeed set at the start of each CMA-ES descent the initial mean m to a point selected uniformly at random in the BBOB search space, and the initial variance to 1/4 of the search space width. Regarding start, the usual setting is of the order of magnitude of ten. In order to obtain the best parallel speedups and to compare our strategies on a large number of CPU cores within a single setting.\n\n4See: https://github.com/cma-es/c-cmaes"
    },
    {
        "id_": "24753d24-d18e-442f-a68a-3cceca8555e4",
        "text": "we target the processing of each evaluation on a dedicated CPU core (see Section 3.2.1). For our MPI+OpenMP performance tests on Fugaku, we thus choose to have start = 12. This way we can have T = 12 threads in each MPI process: the K ⇥ start evaluations of a K descent are thus performed with K MPI processes with T threads each. Each A64FX runs 4 such MPI processes, i.e. one per CMG as usually done with NUMA architectures. For K-Replicated we set Kmax to 29 which leads to Kmax ⇥ start = 29 ⇥ 12 = 6144 parallel evaluations executed on 6,144 cores (512 CMGs, 128 A64FX) for the final descent. For K-Distributed, we set Kmax to 28 which leads to (P8=0 2i) ⇥ start = 511 ⇥ 12 = 6132 parallel evaluations on 511 CMGs. The K-i Distributed strategy thus uses 12 fewer cores than the K-Distributed one, but this is the fairest comparison we can make between these two strategies. We let the sequential IPOP-CMA-ES execute with Kmax = 29, and we ensure that this is the sole process running on the CMG of its core, so as to prevent cache interference with other processes. To keep our experiments manageable in a reasonable time, the execution limit of all experimented algorithms is 12 hours of wall-clock time. Except for Section 4.2 (BLAS/LAPACK tuning), we conducted 20 runs for each function and each strategy in dimensions 10 and 40. Due to time constraints, we performed at least 5 runs for each in dimensions 200 and 1000. The results presented in these sections are aggregated over these multiple runs, with the aggregation methods detailed later."
    },
    {
        "id_": "e77975e0-d775-4b12-bf5c-e26498a5ec60",
        "text": "# 4.2 Linear algebra performance results\n\nWe start our analysis by studying the performance impact of introducing BLAS/LAPACK routines in three linear algebra steps as described in Section 3.1. Figure 5 presents the performance gains with respect to each step, each step being executed sequentially for various dimensions and for various K values, with start = 12.\n\nMore precisely, the upper-left sub-figure reports the performance gain of using LAPACK specifically with respect to the eigendecomposition operation in CMA-ES. LAPACK enables us to accelerate the eigendecomposition step for problems of dimensions 40 and above, and significantly for problems of dimensions 200 et 1000 (up to 15.3x), where the C matrix is large enough to benefit from the LAPACK performance optimisations. Notice that for a relatively small dimension of 10, we found that using LAPACK leads to a performance loss, which is because the matrices maintained by CMA-ES are so small for such a dimension. However, since in dimension 10 the eigendecomposition accounts for only 9% of the overall linear algebra runtime (averaged over the 24 functions of BBOB), the overall loss in performance is negligible.\n\nThe upper-right part of Figure 5 presents BLAS performance gains with respect to the adaptation of the C covariance matrix. We distinguish here gains obtained when directly using Level 2 BLAS in equation 2 (see Section 2.1), and gains obtained with Level 3 BLAS thanks to our rewriting proposed in Section 3.1. While the use of Level 2 BLAS does not offer performance gains in dimensions 10, 40 and 200, our new computation scheme based on Level 3 BLAS offers very significant performance gains (up to 190x), especially for higher problem dimensions. The extra affectations (see Section 3.1) are thus offset by the BLAS gain, even for the lowest dimension.\n\nAs for the sampling operations, as reported in the lower-left sub-figure, we observe that using Level 2 routines directly in equation 1 (see Section 2.1) can only provide some gain for dimensions greater than 10. However, when the operations are rewritten using Level 3 routines (see Section 3.1), we are able to accelerate the reference C code for any dimension, with gains stronger than for Level 2 BLAS. Again the extra affectations (see Section 3.1) are offset by the BLAS gains.\n\nFinally, in the lower-right part of Figure 5, we report performance gains due to the sampling operations, but this time in a different context. The gain is computed with respect to all the linear algebra part (i.e. both sampling at lines 4-5 and update at line 8 in Algorithm 1), and not just to the sampling step like in the lower-left sub-figure. The eigendecomposition"
    },
    {
        "id_": "91013f3d-369b-47b2-a403-6ea712f88202",
        "text": "# Figure 5\n\n(upper-left) Performance gains for the eigendecomposition of the C matrix when using LAPACK over the reference C code (written without LAPACK). (upper-right, resp. lower-left) Performance gains for the adaptation of the C matrix (resp. for the sampling) when using Level 2 or Level 3 BLAS over the reference C code (without BLAS). (lower-right) Performance gains over the reference C code (without BLAS and LAPACK) for all the linear algebra part, with LAPACK for the eigendecomposition and Level 3 BLAS for the C matrix adaptation, when using Level 2 or Level 3 BLAS routines for the sampling. The IPOP columns correspond to a IPOP-CMA-ES execution with successive descents using K from 1 to 28.\n\nuses LAPACK and the matrix adaptation uses Level 3 BLAS, whereas Level 2 or Level 3 BLAS are used for the sampling. Although the gains obtained solely for the sampling may be deemed relatively small compared to the ones obtained solely for the covariance matrix adaptation, using Level 3 BLAS for the sampling operations still has a relatively substantial impact when LAPACK and BLAS routines are already used to optimize the other linear algebra steps. For instance, this enables us to increase the overall gain over the C reference code from 1.5 to 2.5 for all the linear algebra operations in dimension 1000. As a final remark, regarding the sampling and the adaptation steps, one can see stronger gains for K = 28 and for IPOP-CMA-ES than for K = 1: this is due to the larger population sizes, which lead to larger matrices. This shows that BLAS/LAPACK routines are even more relevant for IPOP-CMA-ES than for CMA-ES, the IPOP-CMA-ES increasing population sizes becoming eventually larger than the CMA-ES ones.\n\nTo further illustrate the impact of linear algebra operations, Table 1 presents the proportion of CPU time these operations consume relative to the total execution time of IPOP-CMA-ES, with and without Level 3 BLAS / LAPACK routines. As we can see, BLAS/LAPACK\n\n|Operation|CPU Time with Level 3 BLAS / LAPACK|CPU Time without Level 3 BLAS / LAPACK|\n|---|---|---|\n|Linear Algebra Operations| | |"
    },
    {
        "id_": "c0ee7467-4868-4072-89d8-dbcfbf64cc6a",
        "text": "# Table 1: Proportions (averaged over all BBOB functions) of the linear algebra runtime within the overall runtime of a sequential execution of IPOP-CMA-ES (with start = 12 and Kmax = 28).\n\n|Dimension|Level 3 BLAS / LAPACK|10|40|200|1000|\n|---|---|---|---|---|---|\n|no|38%|36%|44%|69%| |\n| |33%|21%|18%|21%| |\n\nbecomes increasingly effective at reducing the proportion of linear algebra computations as the dimension increases. High dimensionality is a key factor that makes an optimization problem hard, making our linear algebra rewrites particularly valuable for tackling harder problems. Thanks to our BLAS/LAPACK rewrites, the linear algebra part is now a minority in the overall IPOP-CMA-ES runtime. Using additional costs for the evaluations (see Section 4.1) will make the linear algebra part even more minority.\n\nFinally, we tuned our BLAS/LAPACK implementations to determine the optimal number of threads (up to a maximum of 12) for each dimension. We found that dimensions 10 and 40 run best with 1 thread, dimension 200 with 4 threads and dimension 1000 with 12 threads. This aligns with the observation that larger dimensions entail larger matrices, which can be effectively managed by BLAS/LAPACK with a greater number of threads. However, the sizes of the involved matrices are not large enough, and the best speedup we obtain for running BLAS/LAPACK on multiple threads is 1.4×, for dimension 1000 with 12 threads. Due to this limited speedup, we believe that we would not benefit from distributing the linear algebra operations over multiple MPI processes (i.e. over more than 12 cores). That is why we chose to perform the linear algebra operations in parallel using only multi-threading within one MPI process (the main one for each descent, see Section 3.2.1), and up to 12 threads.\n\nNow that we have accelerated the linear algebra operations, with BLAS/LAPACK routines and as much as possible via parallelism, the time spent on function evaluations is the majority in the IPOP-CMA-ES execution time; hence, making the relevant parallelization of function evaluations of high importance. We will thus now focus on our two proposed parallel strategies."
    },
    {
        "id_": "9da3458a-2e2f-4d03-bfb3-1dfabc8fcdc3",
        "text": "# 4.3 Parallel performance results\n\nIn this section, we delve into the performance behavior of the proposed K-Replicated and K-Distributed parallel algorithms. A thorough and fair performance assessment of our parallel variants requires to discuss two aspects. Firstly, although the function evaluation time can significantly influence the overall performance, it cannot be explicitly controlled in the COCO implementation of the BBOB functions. Hence, one has to adopt a more robust approach to assessing parallel performance relative to function evaluation time. Secondly, due to the stochastic nature of the considered algorithms, K-Replicated and K-Distributed are not expected to deliver exactly the same output as the sequential IPOP-CMA-ES. Consequently, it is essential to carefully define a metric that allows us to fairly evaluate the ability of the different algorithms to reach high-quality solutions within reduced time-frames. Therefore, in the next subsection, we begin by discussing the methodology we adopt to address these two aspects. Subsequently, we present our findings and state our main results."
    },
    {
        "id_": "fe52479d-ceae-43af-8a42-1fbdd9d6b51c",
        "text": "# 4.3.1 Performance assessment methodology\n\nFunction evaluation time. We first emphasize the relevance of the additional costs introduced in Section 4.1, by reporting in Figure 6 the share of MPI communications in the total runtime of a K = 28 descent involving 256 MPI processes. When considering zero additional"
    },
    {
        "id_": "468b9ec5-1ddf-42d5-8115-d343f3491afb",
        "text": "# Figure 6\n\nMPI communication shares with respect to the total runtime, as measured by the Fugaku Instant Performance Profiler (FIPP) [68] for a K = 28 descent with 256 MPI processes, averaged over all BBOB functions of dimension 40. ‘main‘ is the main MPI process (namely, the one with rank 0) driving the K = 28 descent (see Section 3.2.1) and processing the linear algebra operations (see end of Section 4.2), whereas ‘evaluator‘ is one of the MPI processes performing only evaluations (here, the one with the highest MPI rank). Contrary to Table 1, we consider only K = 28 and all the evaluations are performed in parallel."
    },
    {
        "id_": "45400c7c-7b79-41f5-84eb-6ece212f03c9",
        "text": "# Figure 7\n\nFunction quality of the best solution found over runtime, averaged over 20 runs using the Expected Runtime (ERT) [22].\n\n15"
    },
    {
        "id_": "d808a1b5-185e-405b-a83b-25b718eb706e",
        "text": "# Cost and Performance Analysis\n\nThe time spent in MPI communications (scatter and gather operations, see Section 3.2.1) is limited for the main process, but is the vast majority of the total time for another process involved in the parallel descent. This is due to the linear algebra part, only performed in the main process and leading to important waiting times for processes other than the main one in their MPI communications (namely at the scatter level). The linear algebra part can thus be a potential performance bottleneck when scaling on a large number of CPU cores.\n\nWhen adding extra costs in the function evaluation, one can see in Figure 6 that the MPI communication shares (i.e. the relative cost of the linear algebra part with respect to the total time, as well as the data transfers themselves) strongly decrease with an increasing additional cost, until becoming a minority. These extra costs enable us to also simulate real-life cases (see Section 4.1) where the linear algebra is not a performance bottleneck."
    },
    {
        "id_": "60c84692-c554-4388-b8ed-3ebadd4f8a5e",
        "text": "# Solution Quality\n\nSince the optimal solutions of the BBOB functions are known, we can evaluate the quality of a solution relative to the optimal one. In our work, we measure quality by the difference ε between the function value of the best solution found so far by an algorithm and the function’s optimal value. However, since the considered algorithms are stochastic, we get inspiration from the so-called Expected Runtime (ERT) [22] in order to aggregate the quality results obtained from multiple runs using different seeds for the same algorithm. More specifically, the ERT defines the empirical average time (over the different seeds) it takes for an algorithm to hit a solution of a given target quality ε.\n\nNotice that two scenarios can happen. In the case all the runs of an algorithm were successful to hit the target quality ε, the ERT is simply the average (over all runs) of the hitting times. In the case some runs were unsuccessful in hitting a target quality within the maximum affordable budget, we can assume that the algorithm could have been restarted for a new run until a success is observed (which is typically the case for stochastic algorithms such as ours). The time until a new run is successful can then be viewed as a random variable, which average value can be empirically estimated in a straightforward manner using the data available from the (other) successful runs at hand. Hence, the ERT value is simply defined as the sum of the execution times of all runs (including unsuccessful ones) divided by the number of successful runs. Notice that for the ERT to be correctly defined, at least one run must be successful. The reader is referred to [22] for more details.\n\nIn all our algorithms, it is easy to track the quality of the best solution found so far over time. Hence, we can easily compute the ERT of an algorithm when considering different targets. Consequently, we can report the expected convergence profile of an algorithm, as shown in Figure 7 on four illustrative BBOB functions. The reported convergence profile suggests a number of important issues to be carefully considered when assessing the relative performance of algorithms. Firstly, we can see that the relative behavior of the three algorithms depends on the tackled function, i.e., no algorithm is better than all others for all functions. Importantly, the relative performance of an algorithm depends on the considered target quality.\n\nWe can also see that not all algorithms can hit the same range of targets on all functions. Some algorithms are even not able to reach the same target that other algorithms can reach for the same function. Consequently, such observations raise a number of qualitative and quantitative questions, i.e., which algorithm is able to reach a given quality? Which algorithm reaches it faster than the others? What relative speedup can be obtained for a given solution quality? etc. In particular, parallel speedups cannot be defined in the conventional manner used in parallel computing. Instead, in our work, we consider nine fixed target quality values, namely ε ∈ {10², 10¹.5, 10¹, 10⁰.5, 10⁰, 10², 10⁴, 10⁶, 10⁸}. These values are actually the same as the ones used in the COCO framework [27]. Roughly speaking, this is intended to represent a range of target quality going from easy, to moderate and difficult to achieve. For each given pair of BBOB function and target quality ε, we can then fairly analyze the relative ERTs achieved by the three algorithms. More specifically, in the following section, we define the speedup achieved."
    },
    {
        "id_": "ba321a30-23ce-44d9-8b50-943e9d12e1ee",
        "text": "# Table 2: Speedups obtained by the two parallel strategies over the sequential IPOP-CMA-ES\n\nAggregated over the different pairs of BBOB functions and target qualities, for various function dimensions and function granularities. ’¡’ (resp. ’¿’) stands for the number of function-target couples for which K-Replicated reaches the target quality before (resp. after) K-Distributed. Function-target couples are accounted for when both parallel algorithms reach the target quality, so the sum of the counts may vary with the dimension and the granularity.\n\n|Dimension|10|10|10|10|40|40|40|40|200|1000|\n|---|---|---|---|---|---|---|---|---|---|---|\n|Additional cost|0|1ms|10ms|100ms|0|1ms|10ms|100ms|0|0|\n|K-Replicated avg. speedup|1.1|83|159|219|8.6|70|160|176|59|23|\n|std. dev.|4.0|234|432|639|24|171|520|618|183|55|\n|min. speedup|0.1|0.1|0.6|3.7|0.0|0.1|0.5|3.9|0.1|0.1|\n|max. speedup|30|1620|2995|5018|206|1182|3861|5121|1614|425|\n|/>|13/182|15/182|10/188|23/170|9/173|9/174|13/170|35/148|28/134|20/107|\n|K-Distributed avg. speedup|2.7|115|201|169|17|171|419|736|392|70|\n|std. dev.|3.2|259|378|255|39|302|799|2884|1580|257|\n|min. speedup|0.5|0.6|2.1|7.7|0.3|0.7|1.8|8.0|0.3|0.5|\n|max. speedup|20|1610|1901|2071|267|1645|3857|18080|13944|2397|"
    },
    {
        "id_": "223943f9-803d-4ec4-b868-41b8bf9aaa1e",
        "text": "# 4.3.2 Overall parallel speedup\n\nIn Table 2, we summarize some basic statistics concerning the speedups obtained by our two parallel strategies over the sequential IPOP-CMAE-ES. This sequential IPOP-CMA-ES leverages our Level 3 BLAS / LAPACK rewrites (with one thread) so as to focus here on the speedups obtained thanks to MPI+thread parallelism. More precisely, Table 2 reports the average, the standard deviation, the minimum and the maximum, speedups obtained respectively by K-Replicated and K-Distributed over the different pairs of BBOB functions and target qualities. The results are reported for each considered function dimension and function granularity. Additionally, the row ”¡/¿” of Table 2 offers a direct comparison: each function-target pair is counted in the left-hand (resp. right-hand) number when K-Replicated reaches the target quality before (resp. after) K-Distributed. For example, the first cell with value 13/182 reads as K-replicated has better ERT than K-Distributed on 13 function-target pairs, whereas K-Distributed has better ERT than K-replicated on 182 function-target pairs.\n\nTwo main observations can be extracted from Table 2. Firstly, we can clearly see that K-Distributed (despite using a little less CPU cores) provides almost always a better average speedup than K-Replicated. The only exception is for dimension 10 with 100ms additional cost. Interestingly, even in such a case, as shown in the ”¡/¿” row, the number of function-target pairs where K-Distributed is faster than K-Replicated is substantial. In fact, this holds true with no exception independently of the setting of the dimension and of the function additional cost. Moreover, we managed to obtain very high maximum speedups (over functions and targets) for both strategies, as soon as the computation grain or the dimension are large enough. It is also interesting to note that we even obtain ’super-linear’ speedups for K-Distributed. This happens for dimension 40 with a function additional cost of 100ms, as well as for dimension 200, where the maximum observed speedup of K-Distributed is respectively 18080⇥ for function f7 with target 106, and 13944⇥ for f18 with 102, which is substantially larger than the 6144 cores used. One should indeed recall that the considered parallel strategies do not imply exactly the same search behavior as serial IPOP-CMAE-ES. Hence, these results."
    },
    {
        "id_": "0648ac5e-b428-4311-81c2-4f900ae29c57",
        "text": "# Table 3: Speedups of K-Distributed over K-Replicated for all targets and functions in dimension 40 with an additional cost of 100ms.\n\nCells where K-Distributed is faster than K-Replicated (speedup > 1) are in bold font. ’X’ indicates that K-Distributed did not reach the target. ’-’ indicates that no parallel strategy reached the target.\n\n|Function|Targets| | | | | | | | | | | |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| |102|101.5|101|100.5|100|104|106|108| | | | |\n|1|**0.6|0.9|0.9|1.0|1.0|1.2|1.3|1.4|1.4**| | | |\n| |2|**7.5|9.0|10|11|12|14|14|13|13**| | |\n|3|**1.2|5.7**|X|-|-|-|-|-|-| | | |\n| | | |4|**1.4|7.7**|-|-|-|-|-|-|-|\n| |5|**1.4|1.6|1.8|1.9|2.0|2.2|2.3|2.3|2.4**| | |\n| | | |6|**1.0|1.1|1.3|1.4|1.5|1.9|2.2|2.4|2.4**|\n|7|**1.0|1.1|1.3**|49|495|508|508|508|495| | | |\n| | | |8|**1.1|0.9|2.6|2.7|2.7|2.9|3.0|2.9|2.9**|\n| |9|**1.2|0.8|3.2|3.4|3.5|3.7|3.9|3.9|3.8**| | |\n|10|**8.7|9.5|11|12|13|15|15|15|14**| | | |\n| |11|**24|22|22|22|22|20|19|17|16**| | |\n| | |12|**1.3|1.3|1.2|1.2|1.1|0.9|1.4|2.0|2.2**| |\n| | | |13|**1.1|1.1|1.2|1.2|1.2|1.5|2.5|5.7|7.2**|\n| | |14|**2.0|0.6|0.8|0.9|1.0|1.3|4.2|9.7|16**| |\n| | |15|**1.2|5.9|11|14|14|12|11|11|10**| |\n| | | |16|**1.7|1.1|1.0|1.1|1.5|50|23|26|29**|\n| | | |17|**2.1|2.2|1.0|1.0|1.2|2.6|11|13|13**|\n|18|**1.7|0.8|1.1|1.3|1.5|12|32|40|38**| | | |\n|19|**1.5|2.2|1.0|2.6|3.1**|-|-|-|-| | | |\n|20|**0.9|0.9|0.9|0.8|8.1**|-|-|-|-| | | |\n|21|**1.4|0.8|0.8|0.7|0.1|0.1|0.2|0.2|0.2**| | | |\n|22|**1.8|0.7|0.7|0.8|0.0**|-|-|-|-| | | |\n|23|**2.0|2.0|1.9|0.9|0.4|1.2**|-|-|-| | | |\n|24|**1.0|2.1|3.7|4.5|13**|-|-|-|-| | | |\n\nSupport the fact that, for some specific functions/targets, the considered parallel strategies are able to show better search behavior than the original serial algorithm. To further illustrate the superiority of K-Distributed, we show in Table 3 a detailed view of the corresponding speedups obtained over K-Replicated for dimension 40 and an additional evaluation cost of 100ms. We clearly observe that K-Distributed is the faster solver for most targets. Notice that the relative speedup on function 7 is very high, K-Distributed being more than 500× faster than K-Replicated, which is because K-Replicated is particularly inefficient for this function (as further detailed in Section 4.4). Besides, it is interesting to note that not all targets can be hit by the algorithms for any function which is specifically because some BBOB functions are more difficult to optimize than others. For the clarity of the presentation, a more thorough discussion of this important aspect is delayed to later.\n\nSecondly, we can clearly see in Table 2 that the function evaluation granularity as captured by the considered additional costs has a deep impact on the obtained speedups. Except for one case (when increasing the additional cost from 10ms to 100ms in dimension 10 for K-Distributed), the speedup of the parallel strategies over the serial algorithm increases indeed consistently with the function evaluation cost.\n\nAt this stage of the presentation, let us remark that although Table 2 provides a global view of the speedups the parallel strategies can achieve over the serial algorithm, the reported statistics are still to be very carefully interpreted. In particular, computing a speedup value can only be performed when both the sequential IPOP-CMAE-ES and the parallel strategy were successful in hitting a given target. This means that the average speedup values as shown in Table 2 discard the pairs of function/target where at least one algorithm was not able to hit the considered target. Generally speaking, we observed that the harder a target is, the more likely it is for serial IPOP-CMA-ES to be unsuccessful. This is exactly why the overall average speedup values reported in Table 2 decreases when going from dimension 200 to dimension 1000."
    },
    {
        "id_": "3b6461cb-d8b7-4d39-9447-db0415eeda4e",
        "text": "# 4.3.3 Empirical cumulative distribution analysis\n\nIn this section, we analyze the relative performance of the considered algorithms using the so-called Empirical Cumulative Distribution Functions (ECDF) [46] as introduced in the COCO benchmarking framework6. Generally speaking, an empirical (cumulative) distribution function F : R ! [0, 1] is defined for a given real-valued data set, such that F (t) equals the fraction of elements in the data which are smaller than or equal to t. In an optimization setting, the ECDF is to be viewed as a measure of how many ’problems’ a stochastic optimization algorithm can solve on average for a given time budget t. More specifically, for the purpose of our analysis, we consider the set containing the (function,target,run)-triplets labeled with the timestamp at which the algorithm was able to find a solution hitting a specified target value. The ECDF then counts for every timestamp t the proportion of (function,target,run)-triplets labeled with a timestamp smaller than or equal to t. In other words, the ECDF counts the proportion of targets that an optimization algorithm is able to hit as a function of the elapsed time t, i.e., the higher the proportion, the more powerful an algorithm.\n\nIn Figures 8 a) b) c) d), we present the ECDF curves for each algorithm across all dimensions (without additional cost). On an ECDF graph, a curve positioned to the left of another one for a given ECD value indicates a more powerful algorithm. Notably, K-Distributed’s curve.\n\n|(a)|Dimension 10 (no additional cost)|\n|---|---|\n|(b)|Dimension 200 (no additional cost)|\n|(c)|Dimension 1000 (no additional cost)|\n|(d)|Dimension 40 (no additional cost)|\n|(e)|Dimension 40, additional cost of 1ms|\n|(f)|Dimension 40, additional cost of 100ms|\n\nHowever, such a decrease is not to be attributed to a parallel performance loss as the problem dimension decreases. It is instead to be attributed to the fact that many target values cannot be hit by serial IPOP-CMA-ES. Hence, a more fine grained assessment of the behavior of the different parallel strategies is needed to fully appreciate the benefits of the designed strategies, in particular as a function of problem dimension. This is to be studied in more detail in the next section introducing more advanced statistics."
    },
    {
        "id_": "36206fdc-c937-4936-b886-e4f04f1a1787",
        "text": "# Table 4: ECD value reached by each algorithm for the final timestamp of K-Distributed for various dimensions and granularities.\n\n|Dimension|10|10|10|10|40|40|40|40|200|1000|\n|---|---|---|---|---|---|---|---|---|---|---|\n|Additional cost|0|1ms|10ms|100ms|0|1ms|10ms|100ms|0|0|\n|Sequential IPOP|72%|31%|24%|21%|67%|34%|34%|33%|48%|39%|\n|K-Replicated|29%|82%|83%|83%|75%|74%|78%|78%|65%|57%|\n|K-Distributed|82%|82%|83%|82%|78%|79%|79%|80%|75%|64%|\n\nis almost always the leftmost which suggests that, without specific knowledge of a function landscape, K-Distributed is the superior choice. Similarly, K-Replicated’s curve is to the left of the the sequential IPOP-CMA-ES one for most of the execution time. The ECDF analysis thus confirms the conclusions from Section 4.3.2: both parallel strategies outperform the sequential IPOP-CMA-ES, with K-Distributed being the most effective.\n\nNext, we analyze the dynamics of the algorithms with respect to function dimension. Firstly, higher dimensions show a larger gap between the parallel variants and the sequential IPOP-CMA-ES, leading to greater speedups for the parallel variants. Secondly, for each dimension, there is a cross-over ECD value where each parallel curve crosses and stays to the left of the sequential curve, meaning the parallel variant is generally better than sequential IPOP-CMA-ES for solving problems past this point. Sequential IPOP-CMA-ES is therefore faster only for the very easiest targets and, as the dimension increases, these cross-over values decrease, making the parallel variants the better choice for a broader range of problems. Thirdly, in Table 4, we report the ECD values for each algorithm at the final timestamp of the K-Distributed strategy. We observe that ECD values decrease with increasing dimension, especially at dimensions 200 and 1000. However, for these high dimensions, the parallel strategies show greater ECD values than the sequential IPOP-CMA-ES, K-Distributed having the greatest ones. Thus, as dimension increases (which makes optimization problems more challenging), the benefits of our parallel variants, particularly K-Distributed, become more pronounced.\n\nIn Figures 8 d) e) f), we report ECDF curves for different granularities at dimension 40 (dimension 10 leads to similar results). As with dimension, a higher granularity widens the gap between the parallel strategies and the sequential IPOP-CMA-ES. Additionally, a higher granularity increases the gap between K-Distributed and K-Replicated for ECD values greater than 0.4, making K-Distributed a better choice for more time-consuming problems.\n\nFinally, we observe specific effects in certain dimensions and granularities. In dimension 1000 (see Figure 8c), the sequential IPOP-CMA-ES stops at a lower ECD value due to the time limit, which prevents us from computing parallel speedups for many targets hit by our parallel strategies (see Section 4.3.2 and the lower average speedups for dimension 1000 in Table 3). However, past the last ECD value reached by sequential IPOP-CMA-ES, the slope of the curves for the two parallel strategies do not bend, showing that these parallel strategies are actually highly efficient in high dimension. This is why, along with the parallel speedups, ECDF profiles are necessary to appreciate the full extent of the performance of our strategies. To finish with, in dimensions 10 and 40 for all granularities, K-Replicated’s final runtime reaches slightly more targets than K-Distributed, but only long after K-Distributed is over. This is because we have let K-Replicated run up to Kmax = 29 (as opposed to Kmax = 28 for K-Distributed) and because K-Replicated’s design involves more descents. This enables K-Replicated to perform more exploration, at the cost of a much greater budget than K-Distributed."
    },
    {
        "id_": "70eb33c2-cffe-4c00-9577-d387ab13224a",
        "text": "# Figure 9:\n\nFunction quality over the ERT for the different population sizes of K-Distributed."
    },
    {
        "id_": "b9d6821e-9198-43f6-8055-a0d8da05302d",
        "text": "# Table 5:\n\nlog2K (averaged over 20 executions) of the first descent to reach a given quality for a K-Distributed run in dimension 40 (no additional cost). ’-’ indicates that no descent reached the target.\n\n|function| | |targets| | | | | | | |\n|---|---|---|---|---|---|---|---|---|---|---|\n| | |102|101.5|101|100.5|100|104|106|108| |\n| |1|0.1|0.1|0.1|0.1|0.1|0.1|0.1|0.1| |\n| |2|2.2|2.4|2.4|2.7|2.8|3.0|2.8|2.8| |\n| |3|0.7|3.0|-|-|-|-|-|-| |\n| |4|1.3|5.1|-|-|-|-|-|-| |\n| |5|0.1|0.1|0.1|0.0|0.1|0.1|0.1|0.1| |\n| |6|0.1|0.1|0.1|0.3|0.4|1.1|1.0|1.2|1.3|\n| |7|0.3|0.6|1.9|3.9|4.5|4.8|4.8|4.8| |\n| |8|0.3|0.7|1.4|1.6|1.6|1.7|1.8|1.8|1.9|\n| |9|0.3|0.8|1.7|1.9|1.9|2.0|2.0|1.9|1.9|\n| |10|1.8|1.6|1.8|1.7|1.9|2.0|2.0|2.0|2.1|\n| |11|3.0|2.9|2.9|3.0|2.8|2.6|2.6|2.5|2.6|\n| |12|0.2|0.3|0.7|0.9|1.1|1.2|1.2|1.6|1.6|\n| |13|0.0|0.1|0.1|0.7|1.2|2.4|2.6|3.1|3.1|\n| |14|0.1|0.0|0.0|0.0|0.0|0.1|1.5|2.4|2.6|\n| |15|0.6|2.1|4.2|5.6|6.4|6.5|6.5|6.5| |\n| |16|0.5|1.0|1.2|0.9|1.6|6.9|7.2|7.5|7.0|\n| |17|0.0|0.0|0.0|0.0|0.3|1.5|2.4|3.5|4.0|\n| |18|0.1|0.1|0.1|0.5|1.2|3.7|5.4|5.7|5.7|\n| |19|0.0|0.0|0.1|1.6|1.9|-|-|-|-|\n| |20|0.0|0.1|0.1|0.0|6.9|-|-|-|-|\n| |21|0.6|0.1|0.1|2.0|2.5|2.3|2.3|2.3|2.3|\n| |22|0.0|0.1|1.4|1.4|1.0|-|-|-|-|\n| |23|0.2|0.2|0.2|5.0|1.9|3.3|-|-|-|\n| |24|1.0|4.2|5.0|5.7|-|-|-|-|-|"
    },
    {
        "id_": "69f4f1f2-67f7-4d91-a5b4-4c50522f569e",
        "text": "# 4.4 Impact of the population size\n\nIn this section, we analyze the effect of the population size on K-Distributed’s performance in order to analyze its superior performance. We start by reporting in Figure 9 the convergence profiles for each distinct population size of K-Distributed on three illustrative BBOB functions. We observe that the fastest population size to reach a function quality varies depending on the targeted function and quality. For the first (i.e. the easiest) function qualities, or for functions with a very simple shape (such as a sphere for f1), the descents of K-Distributed are ordered by K value (hence by population size): the K = 20 descent is better than the K = 21 one, which is better than the K = 22 one, and so forth. However, for harder function qualities, and for more complex function (such as f17), some descents may stop being competitive after a given time. They typically reach this time in the order of K: first 20, then 21, etc. After a descent reaches such a time, the descent with the next larger population size becomes the most time-effective. We also see that the time before a descent stops being effective can vary greatly with the population size. Finally regarding f7, its shape consists in a step ellipsoidal function which includes many small regions with null gradients. A solver needs good global."
    },
    {
        "id_": "d0076208-f840-4147-ba9b-b4a2e1c1142b",
        "text": "# Figure 10:\n\nSpeedup of K-Distributed (over sequential IPOP-CMA-ES) against the best population size for function-target couples, averaged over 20 executions, for dimension 40, with (right) and without (left) additional cost.\n\nSearch abilities to find the optimum, which translates to a large population descent for CMA-ES. For this function, sequential IPOP-CMA-ES and K-Replicated waste CPU time with the first small population descents which last long (especially K = 20) and deliver limited qualities. This explains in particular the large performance gap between K-Distributed and K-Replicated on f7 in Table 3. To sum up, this overall dynamic shown in Figure 9 makes it difficult to predict which population size will be best for a given problem.\n\nTo confirm this analysis, we report in Table 5 the average log2K of the first descent to find a solution for different functions and targets. We see that lower population sizes are better suited for the first targets (i.e. for the columns with the highest power of 10). However, for other targets the best population size varies widely, with log2K ranging from 0.1 to 7.5. Note that these targets are more difficult to solve and correspond to the highest speedups of K-Distributed over sequential IPOP-CMA-ES. Besides, the best population size changes with each function for the final target (column with 108), and also with the target for each function. From this, we conclude that no population size is inherently better than another. Since we lack a reliable way to predict which population size will be more effective, the best strategy is to give an equal chance to each size and start them all at the beginning of the execution, which is precisely how K-Distributed operates.\n\nWe want to emphasize that K-Distributed’s efficiency also relies on our parallel evaluations. Since in our K-Distributed design the number of cores used is proportional to the population size, the speedups are greater for larger population sizes, which makes the duration of the iterations closer among different population sizes. As a result, the convergence of each descent operates on a more similar time scale. Without such a parallel evaluation, the descent with larger population sizes would require much more time and would be less competitive compared to the ones with lower population sizes.\n\nLastly, we report in Figure 10 the speedups for K-Distributed over sequential IPOP-CMA-ES depending on the best population size for each target. One can first notice when comparing the two plots that K-Distributed’s large populations lead to greater speedups when the function evaluation cost is longer. This is because longer evaluation times make the descents less sensitive to the costs of MPI communications and of linear algebra. Descents with large K values can\n\n22"
    },
    {
        "id_": "d7294cca-968b-4a60-ada8-8390cf9957bd",
        "text": "# then benefit at best from their higher parallel evaluation speedup. One can also see that K-Distributed’s highest speedups are obtained for the larger population sizes. This is due to sequential IPOP-CMA-ES performing descents in an increasing order of population size, taking more time to start descents of larger populations (which also applies partly to K-Replicated). On the contrary, K-Distributed starts all descents concurrently which is beneficial when a large population is the most relevant for solving a given problem. In some instances, this can even produce super-linear speedups as presented in Section 4.3.2."
    },
    {
        "id_": "f9756626-4445-4fec-827c-fcdf549f157f",
        "text": "# 5 Conclusion\n\nIn this paper, we investigated two parallel strategies for the IPOP-CMA-ES (Covariance Matrix Adaptation Evolution Strategy with Increasing Population) algorithm, designed for large black-box optimization problems on thousands of CPU cores. Both strategies leveraged BLAS and LAPACK routines to accelerate linear algebra operations, which required the rewriting of some operations to successfully benefit from the more efficient Level 3 BLAS. The first approach, K-Replicated, performs multiple descents with identical population sizes, increasing the population size as descents conclude and thus mirroring the progression of IPOP-CMA-ES. On the other hand the second strategy, K-Distributed, adapts IPOP-CMA-ES differently by initiating all descents simultaneously, each with a distinct population size.\n\nThanks to experiments on the supercomputer Fugaku, using MPI+OpenMP implementations on 128 A64FX CPUs of 48 cores each (6144 cores in total), with a reference black-box optimization benchmark extended with coarser computation grains, we determined that these parallel strategies greatly improved on the convergence speed of the original sequential IPOP-CMA-ES, reaching speedups up to several thousand. Notably, K-Distributed outperformed K-Replicated in the vast majority of cases. Moreover, due to its concurrent processing of multiple descents with distinct population sizes, K-Distributed occasionally exhibited super-linear speedups up to 18080× on 6144 cores. We complemented these results with a detailed analysis of the superior performance of K-Distributed. According to our results, if one has a given allocated time on a large-scale parallel architecture, we recommend running K-Distributed and possibly restarting each descent once finished until the time is up.\n\nThis study opens up several interesting research avenues. The large-scale techniques used here could serve as a basis for parallelizing other variants of CMA-ES, such as the large-scale ones [36, 39, 38]. Additionally, the parallel IPOP-CMA-ES algorithm could be integrated with other optimization heuristics, such as global optimization [51] or hyper-parameter tuning [40]. Furthermore, investigating methods to predict the most effective CMA-ES population size for an objective function, either beforehand or at runtime, could strongly benefit both sequential and parallel black-box optimization."
    }
]